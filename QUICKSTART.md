# LongEmotion å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æ–‡æ¡£å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹ LongEmotion æ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [ä¸‹è½½æ•°æ®é›†](#ä¸‹è½½æ•°æ®é›†)
- [æ•°æ®åŠ è½½ç¤ºä¾‹](#æ•°æ®åŠ è½½ç¤ºä¾‹)
- [è¿è¡Œè¯„ä¼°](#è¿è¡Œè¯„ä¼°)
- [æŸ¥çœ‹ç»“æœ](#æŸ¥çœ‹ç»“æœ)

---

## ç¯å¢ƒå‡†å¤‡

### 1. åˆ›å»º Python ç¯å¢ƒ

```bash
# åˆ›å»º conda ç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n LongEmotion python=3.10
conda activate LongEmotion

# æˆ–ä½¿ç”¨ venv
python3 -m venv longemotion_env
source longemotion_env/bin/activate  # Linux/Mac
# longemotion_env\Scripts\activate  # Windows
```

### 2. å®‰è£…ä¾èµ–

```bash
cd LongEmotion
pip install -r requirements.txt
```

### 3. éªŒè¯å®‰è£…

```bash
python -c "import torch; import transformers; print('âœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆ')"
```

---

## ä¸‹è½½æ•°æ®é›†

### æ–¹æ³•1: ä½¿ç”¨æä¾›çš„è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
python download_dataset.py --output_dir ./hf_dataset
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ“ ä» HuggingFace ä¸‹è½½æ•°æ®é›†
- âœ“ éªŒè¯æ•°æ®å®Œæ•´æ€§
- âœ“ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š

### æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½

```python
from huggingface_hub import snapshot_download

snapshot_download(
    repo_id='LongEmotion/LongEmotion',
    repo_type='dataset',
    local_dir='./hf_dataset'
)
```

### æ–¹æ³•3: ä½¿ç”¨å·²æœ‰æ•°æ®

å¦‚æœä½ å·²ç»æœ‰æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥éªŒè¯å®Œæ•´æ€§ï¼š

```bash
python download_dataset.py --skip_download --output_dir ./hf_dataset
```

---

## æ•°æ®åŠ è½½ç¤ºä¾‹

### Python ç¤ºä¾‹

åˆ›å»º `test_load.py`ï¼š

```python
import json
from pathlib import Path

# æ•°æ®ç›®å½•
DATA_DIR = Path("hf_dataset")

# 1. åŠ è½½æƒ…ç»ªåˆ†ç±»æ•°æ®
def load_emotion_classification():
    print("="*60)
    print("åŠ è½½ Emotion Classification (Emobench)")
    print("="*60)
    
    file_path = DATA_DIR / "Emotion Classification/Emotion_Classification_Emobench.jsonl"
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]
    
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"\nç¬¬ä¸€ä¸ªæ ·æœ¬:")
    print(f"  ID: {data[0]['id']}")
    print(f"  Subject: {data[0]['subject']}")
    print(f"  Label: {data[0]['label']}")
    print(f"  Content Length: {data[0]['length']} tokens")
    print(f"  Choices: {data[0]['choices']}")
    print(f"  Content Preview: {data[0]['content'][:200]}...")
    
    return data

# 2. åŠ è½½æƒ…ç»ªé—®ç­”æ•°æ®
def load_emotion_qa():
    print("\n" + "="*60)
    print("åŠ è½½ Emotion QA")
    print("="*60)
    
    file_path = DATA_DIR / "Emotion QA/Emotion_QA.jsonl"
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]
    
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"\nç¬¬ä¸€ä¸ªæ ·æœ¬:")
    print(f"  Number: {data[0]['number']}")
    print(f"  Problem: {data[0]['problem'][:100]}...")
    print(f"  Answer: {data[0]['answer'][:100]}...")
    print(f"  Source: {data[0]['source'][:80]}...")
    
    return data

# 3. åŠ è½½æƒ…ç»ªå¯¹è¯æ•°æ®
def load_emotion_conversation():
    print("\n" + "="*60)
    print("åŠ è½½ Emotion Conversation")
    print("="*60)
    
    file_path = DATA_DIR / "Emotion Conversation/Emotion_Conversations.jsonl"
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]
    
    print(f"æ€»å¯¹è¯æ•°: {len(data)}")
    print(f"\nç¬¬ä¸€ä¸ªå¯¹è¯:")
    print(f"  ID: {data[0]['id']}")
    print(f"  Description: {data[0]['description'][:100]}...")
    print(f"  Stages: {len(data[0]['stages'])} è½®")
    
    for stage in data[0]['stages'][:2]:  # æ˜¾ç¤ºå‰ä¸¤è½®
        print(f"    Stage {stage['stage']}: {stage['content'][:80]}...")
    
    return data

# 4. åŠ è½½æƒ…ç»ªè¡¨è¾¾æ•°æ®
def load_emotion_expression():
    print("\n" + "="*60)
    print("åŠ è½½ Emotion Expression")
    print("="*60)
    
    # Situations
    file_path = DATA_DIR / "Emotion Expression/Emotion_Expression_Situations.json"
    with open(file_path, 'r', encoding='utf-8') as f:
        situations = json.load(f)
    
    print(f"æƒ…ç»ªç±»å‹æ•°: {len(situations['emotions'])}")
    print(f"æƒ…ç»ªç±»å‹: {[e['emotion_name'] for e in situations['emotions'][:3]]}")
    
    return situations

# ä¸»å‡½æ•°
if __name__ == "__main__":
    print("ğŸš€ LongEmotion æ•°æ®åŠ è½½ç¤ºä¾‹\n")
    
    ec_data = load_emotion_classification()
    qa_data = load_emotion_qa()
    conv_data = load_emotion_conversation()
    ee_data = load_emotion_expression()
    
    print("\n" + "="*60)
    print("âœ“ æ‰€æœ‰æ•°æ®åŠ è½½æˆåŠŸï¼")
    print("="*60)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_load.py
```

---

## è¿è¡Œè¯„ä¼°

### 1. é…ç½®æ¨¡å‹

ç¼–è¾‘ `evaluate.sh`ï¼Œè®¾ç½®ä½ çš„æ¨¡å‹é…ç½®ï¼š

```bash
#!/usr/bin/env bash

WORK_DIR=$(dirname $(readlink -f $0))
METHOD=$1   # baseline | rag | coem | self-rag | search-o1
TASK=$2     # ä»»åŠ¡åç§°

PYTHONPATH="${WORK_DIR}/src" python "${WORK_DIR}/evaluate.py" \
  --task "${TASK}" \
  --method "${METHOD}" \
  --data_dir "${WORK_DIR}/hf_dataset" \
  --prompts_dir "${WORK_DIR}/prompts" \
  --base_dir "${WORK_DIR}/evaluations" \
  --model_name "gpt-4o" \
  --model_api_key "your_api_key_here" \
  --model_url "https://api.openai.com/v1" \
  --model_name_coem_sage "gpt-4o" \
  --model_api_key_coem_sage "your_api_key_here" \
  --model_url_coem_sage "https://api.openai.com/v1" \
  --evaluator_name "gpt-4o" \
  --evaluator_api_key "your_api_key_here" \
  --evaluator_url "https://api.openai.com/v1"
```

**æ”¯æŒçš„æ¨¡å‹é…ç½®ï¼š**

#### OpenAI
```bash
--model_name "gpt-4o"
--model_api_key "sk-..."
--model_url "https://api.openai.com/v1"
```

#### DeepSeek
```bash
--model_name "deepseek-chat"
--model_api_key "sk-..."
--model_url "https://api.deepseek.com/v1"
```

#### Claude (é€šè¿‡ OpenAI-compatible endpoint)
```bash
--model_name "claude-3-5-sonnet-20241022"
--model_api_key "sk-..."
--model_url "your_endpoint"
```

#### æœ¬åœ°æ¨¡å‹
```bash
--model_name "Qwen/Qwen2.5-72B-Instruct"
--model_url "local"
```

### 2. é€‰æ‹©è¯„ä¼°æ–¹æ³•

LongEmotion æ”¯æŒ 5 ç§è¯„ä¼°æ–¹æ³•ï¼š

| æ–¹æ³• | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| `baseline` | ç›´æ¥å¤„ç†å…¨æ–‡ | çŸ­æ–‡æœ¬æˆ–å°æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£è¶³å¤Ÿ |
| `rag` | æ£€ç´¢å¢å¼ºç”Ÿæˆ | é•¿æ–‡æœ¬ï¼Œéœ€è¦ä¿¡æ¯æ£€ç´¢ |
| `coem` | åä½œæƒ…ç»ªå»ºæ¨¡ | é•¿æ–‡æœ¬æƒ…ç»ªä»»åŠ¡ï¼ˆæ¨èï¼‰ |
| `self-rag` | è‡ªé€‚åº”æ£€ç´¢ | éœ€è¦åŠ¨æ€å†³ç­–çš„åœºæ™¯ |
| `search-o1` | æœç´¢ä¼˜åŒ– | å¤æ‚æ¨ç†ä»»åŠ¡ |

### 3. é€‰æ‹©è¯„ä¼°ä»»åŠ¡

å¯ç”¨ä»»åŠ¡åˆ—è¡¨ï¼š

```bash
# æƒ…ç»ªåˆ†ç±»
Emotion_Classification_Emobench
Emotion_Classification_Finentity

# æƒ…ç»ªæ£€æµ‹
Emotion_Detection

# æƒ…ç»ªé—®ç­”
Emotion_QA

# æƒ…ç»ªå¯¹è¯
Emotion_Conversations

# æƒ…ç»ªæ‘˜è¦
Emotion_Summary

# æƒ…ç»ªè¡¨è¾¾
Emotion_Expression
```

### 4. è¿è¡Œè¯„ä¼°

ç¼–è¾‘ `run.sh`ï¼š

```bash
#!/usr/bin/env bash

export CUDA_VISIBLE_DEVICES=0

# è¿è¡Œå•ä¸ªä»»åŠ¡
bash evaluate.sh baseline Emotion_Classification_Emobench

# è¿è¡Œå¤šä¸ªä»»åŠ¡
# bash evaluate.sh baseline Emotion_QA
# bash evaluate.sh coem Emotion_Conversations
```

æ‰§è¡Œï¼š

```bash
bash run.sh
```

### 5. æ‰¹é‡è¯„ä¼°æ‰€æœ‰ä»»åŠ¡

åˆ›å»º `run_all.sh`ï¼š

```bash
#!/usr/bin/env bash

export CUDA_VISIBLE_DEVICES=0

METHODS=("baseline" "rag" "coem")
TASKS=(
    "Emotion_Classification_Emobench"
    "Emotion_Classification_Finentity"
    "Emotion_Detection"
    "Emotion_QA"
    "Emotion_Conversations"
    "Emotion_Summary"
)

for method in "${METHODS[@]}"; do
    for task in "${TASKS[@]}"; do
        echo "=========================================="
        echo "è¿è¡Œ: $method - $task"
        echo "=========================================="
        bash evaluate.sh "$method" "$task"
    done
done

echo "âœ“ å…¨éƒ¨è¯„ä¼°å®Œæˆï¼"
```

è¿è¡Œï¼š

```bash
chmod +x run_all.sh
bash run_all.sh
```

---

## æŸ¥çœ‹ç»“æœ

### ç»“æœç›®å½•ç»“æ„

```
evaluations/
â”œâ”€â”€ Emotion_Classification_Emobench/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ results.json
â”‚   â”‚   â””â”€â”€ metrics.json
â”‚   â”œâ”€â”€ rag/
â”‚   â””â”€â”€ coem/
â”œâ”€â”€ Emotion_QA/
â””â”€â”€ logs.txt
```

### æŸ¥çœ‹è¯„ä¼°æŒ‡æ ‡

```python
import json

# è¯»å–ç»“æœ
with open('evaluations/Emotion_Classification_Emobench/baseline/metrics.json', 'r') as f:
    metrics = json.load(f)

print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"Total Samples: {metrics['total']}")
print(f"Correct: {metrics['correct']}")
```

### å¯¹æ¯”ä¸åŒæ–¹æ³•

åˆ›å»º `compare_results.py`ï¼š

```python
import json
from pathlib import Path
from tabulate import tabulate

def compare_methods(task):
    methods = ['baseline', 'rag', 'coem']
    results = []
    
    for method in methods:
        metrics_file = Path(f'evaluations/{task}/{method}/metrics.json')
        if metrics_file.exists():
            with open(metrics_file, 'r') as f:
                metrics = json.load(f)
            results.append([
                method,
                f"{metrics.get('accuracy', 0):.4f}",
                metrics.get('total', 0),
                metrics.get('correct', 0)
            ])
    
    print(f"\n{'='*60}")
    print(f"ä»»åŠ¡: {task}")
    print(f"{'='*60}")
    print(tabulate(results, headers=['Method', 'Accuracy', 'Total', 'Correct']))

# å¯¹æ¯”æ‰€æœ‰ä»»åŠ¡
tasks = [
    'Emotion_Classification_Emobench',
    'Emotion_Classification_Finentity',
    'Emotion_Detection',
    'Emotion_QA',
]

for task in tasks:
    compare_results(task)
```

---

## ğŸ’¡ å°è´´å£«

### 1. èŠ‚çœ API æˆæœ¬

```bash
# å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•
head -10 hf_dataset/Emotion\ QA/Emotion_QA.jsonl > test_data.jsonl

# æˆ–è€…ä¿®æ”¹è¯„ä¼°è„šæœ¬ï¼Œé™åˆ¶æ ·æœ¬æ•°
python evaluate.py --task Emotion_QA --max_samples 10
```

### 2. ä½¿ç”¨ç¼“å­˜

è¯„ä¼°è„šæœ¬ä¼šè‡ªåŠ¨ç¼“å­˜ embedding å’Œæ£€ç´¢ç»“æœï¼Œé‡å¤è¿è¡Œä¼šæ›´å¿«ã€‚

### 3. å¹¶è¡Œè¯„ä¼°

å¦‚æœæœ‰å¤šä¸ª GPUï¼Œå¯ä»¥å¹¶è¡Œè¿è¡Œä¸åŒä»»åŠ¡ï¼š

```bash
# Terminal 1
CUDA_VISIBLE_DEVICES=0 bash evaluate.sh baseline Emotion_QA &

# Terminal 2
CUDA_VISIBLE_DEVICES=1 bash evaluate.sh baseline Emotion_Detection &
```

### 4. ç›‘æ§è¿›åº¦

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f evaluations/logs.txt
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: API è°ƒç”¨å¤±è´¥

```bash
# æ£€æŸ¥ API key æ˜¯å¦æ­£ç¡®
echo $OPENAI_API_KEY

# æµ‹è¯•è¿æ¥
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Q2: å†…å­˜ä¸è¶³

```bash
# å‡å° batch size
# åœ¨ evaluate.py ä¸­ä¿®æ”¹ batch_size å‚æ•°
```

### Q3: æ•°æ®è·¯å¾„é”™è¯¯

```bash
# ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®
ls -la hf_dataset/Emotion\ Classification/

# ä¿®æ”¹ evaluate.sh ä¸­çš„ --data_dir å‚æ•°
```

### Q4: Self-RAG æ¨¡å‹å¯åŠ¨å¤±è´¥

```bash
# ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
ls -la ~/selfrag_llama2_7b

# å¯åŠ¨ vLLM æœåŠ¡å™¨
vllm serve ~/selfrag_llama2_7b \
    --gpu-memory-utilization 0.5 \
    --dtype float16 \
    --port 8010
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

- é˜…è¯» [DATASET_INFO.md](DATASET_INFO.md) äº†è§£æ•°æ®é›†è¯¦ç»†ä¿¡æ¯
- é˜…è¯» [DATASET_README_CN.md](DATASET_README_CN.md) æŸ¥çœ‹å®Œæ•´æ–‡æ¡£
- æŸ¥çœ‹è®ºæ–‡: https://arxiv.org/abs/2509.07403
- è®¿é—® HuggingFace: https://huggingface.co/datasets/LongEmotion/LongEmotion

---

## ğŸ™ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ
- æŸ¥çœ‹ `evaluations/logs.txt` æ—¥å¿—æ–‡ä»¶
- æäº¤ GitHub Issue
- è”ç³»é¡¹ç›®ä½œè€…

---

ç¥ä½ è¯„ä¼°é¡ºåˆ©ï¼ğŸš€
